# Building LLMs is probably not going to be a brilliant business

**Author:** Cal Paterson
**Date:** December 6, 2024
**Source:** https://www.indiehackers.com/post/BX5gHoXc5nzsdTQahXKg

---

## Revenue Numbers Mentioned
- OpenAI funding round: $6.6 billion at $157 billion valuation
- WeWork: Raised over $10 billion at $47 billion valuation, restructured at $0.56 billion
- Coca-Cola: "return on equity has rarely fallen below 30% in any given year"

## Key Lessons

1. **Industry structure determines profitability**, not efficiency or innovation
2. LLM makers face unfavorable competitive dynamics similar to airlines:
   - Single dominant supplier (NVIDIA) with pricing power
   - Low customer loyalty and easy switching between models
   - Abundant competitors with low barriers to entry
   - Viable substitutes exist (human workers, metadata-based solutions)
3. Technology success does not equal business success (containers, browsers, CRMs examples)
4. Building AI models is an "undifferentiated schlep"; better opportunities exist in applications using existing models

## Tech Stack Mentioned
- NVIDIA chips/Hopper microarchitecture (GPU training)
- Cloud vendors: AWS, Google Cloud
- LLM platforms: ChatGPT, Claude, Gemini, Meta's open-source model
- Abstraction layers for model switching

Original source: calpaterson.com/porter.html
