# OpenAI launches real-time voice chat API, image fine-tuning, prompt-caching and more

**Author:** Katie Hignett
**Date:** October 2, 2024
**Source:** https://www.indiehackers.com/post/gQhZdpvFgB9marDnT1bP

---

OpenAI unveiled several developer tools at its annual DevDay, including a low-latency speech-to-speech Realtime API, vision fine-tuning capabilities, prompt caching with cost reductions, and model distillation features. However, the organization did not release full versions of the anticipated o1 model or Sora video-generation tool, nor provided updates on the GPT Store.

The Realtime API enables developers to build voice chat applications with six preset voices and integrates with calling services like Twilio. AI disclosure remains the developer's responsibility. Vision fine-tuning allows GPT-4o models to improve image interpretation, though copyrighted and unsafe images are restricted. Model distillation permits training smaller models using larger ones as a cost-effective alternative. Prompt caching offers "a 50% discount and faster prompt processing times" for frequently-used prompts across GPT-4o and o1 variants.

The announcements coincided with executive departures: CTO Mira Murati, Chief Research Officer Bob McGrew, and VP of Research Barret Zoph all left OpenAI. CEO Sam Altman refocused on product and technical development.

## Key Lessons

- Voice AI infrastructure is becoming accessible to developers
- Cost optimization through model distillation and prompt caching improves economics
- Competitive pressure exists (Anthropic offers 90% vs. OpenAI's 50% prompt caching discount)
- Leadership transitions signal strategic priority shifts

**Tech Stack:** GPT-4o, GPT-4o mini, o1-preview, o1-mini, Twilio
